{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4f7b740",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "1. Load the data.\n",
    "2. Cast text to lower case.\n",
    "3. El,iminate punctuation.\n",
    "4. Get the maximum number of tokens in the data.\n",
    "5. Tokenize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f96de916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f82b4ce3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19956\\457307528.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1216\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1218\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1219\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8fa0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08dd48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lyric'] = data['lyric'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7062b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d975bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_punctuation(text):\n",
    "    text = ''.join([char for char in text if char not in all_punct])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9fc833",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_char = string.ascii_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fad7ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_punct = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19746830",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f072e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lyric'] = data['lyric'].apply(clear_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2fc143",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44969eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lyric_len'] = data['lyric'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c66a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7c178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['lyric_len'] == max(data['lyric_len'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab510634",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data.iterrows():\n",
    "    print(row[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c172dde",
   "metadata": {},
   "source": [
    "The length of the texts are not symmetrical, so we need to pad the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd59fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_text(text, unk = '?', limit = 400):\n",
    "    if len(text) < limit:\n",
    "        text = text + unk*(limit - len(text))\n",
    "    else:\n",
    "        text = text[:limit-1]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2941cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lyric'] = data['lyric'].apply(pad_text, **{\"limit\" : 400, \"unk\" : \"#\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3193c22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689977ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "unidecode(data['lyric'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec366bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_char = '#' + ' ' + all_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a0aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1680765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dict = dict(enumerate(all_char, start = 0))\n",
    "char_dict = {v: k for k, v in char_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44021e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405495e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "        self.texts = self.file['lyric']\n",
    "        self.labels = self.file['class']\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, ix):\n",
    "        return torch.tensor([char_dict[c] for c in self.texts[ix]]), self.labels[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334fd654",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = TextDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6815da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01e97dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data.texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9989b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f14852",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = torch.utils.data.random_split(text_data, lengths = [len(text_data) - 10000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac0f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a068f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e68da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aa5687",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63e9307",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_ds, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bdc2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricModel(nn.Module):\n",
    "    def __init__(self, batch_size = 32, num_layers = 2, bidirectional = True, hidden_size = 128, length = 64):\n",
    "        self.hidden = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.length = length\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.in_features = self.hidden * (int(self.bidirectional) + 1)\n",
    "        \n",
    "        super(LyricModel, self).__init__()\n",
    "        \n",
    "        self.embedder = nn.Embedding(num_embeddings = len(char_dict), embedding_dim = self.length)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = self.length, hidden_size = self.hidden, batch_first = True,\n",
    "                            num_layers = self.num_layers, bidirectional = self.bidirectional)\n",
    "        self.linear1 = nn.Linear(self.in_features, self.in_features//2)\n",
    "        self.linear2 = nn.Linear(self.in_features//2, 1)\n",
    "        self.linear3 = nn.Linear(400, 1)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        y = self.embedder(x)\n",
    "        y, h = self.lstm(y, h)\n",
    "        y = F.leaky_relu(self.linear1(y), .1)\n",
    "        y = F.leaky_relu(self.linear2(y), .1)\n",
    "        y = F.leaky_relu(self.linear3(y), .1)\n",
    "        \n",
    "        return torch.sigmoid(y), h\n",
    "    \n",
    "    def init_hidden_state(self, mean, stddev):\n",
    "        \"\"\"\n",
    "        Initialize hidden state and context tensors.\n",
    "        \"\"\"\n",
    "        h = torch.distributions.Normal(mean, stddev).sample(((int(self.bidirectional) + 1)*self.num_layers,\\\n",
    "                                                             self.batch_size, self.hidden_size))\n",
    "        c = torch.distributions.Normal(mean, stddev).sample(((int(self.bidirectional) + 1)*self.num_layers, \\\n",
    "                                                             self.batch_size, self.hidden_size))\n",
    "        \n",
    "        return (h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21bf947",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LyricModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fafc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "lr = 2e-4\n",
    "betas = (0.9, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322b86dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(params = model.parameters(), lr = lr, betas = betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e627142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e0761",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_losses = 0\n",
    "    train_accs = 0\n",
    "    for i, (X, y) in enumerate(train_dl, start = 1):\n",
    "        opt.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = criterion(pred.squeeze(), y.float())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_losses += loss.item()\n",
    "        train_accs += torch.sum(torch.where(pred > 0.5, 1, 0).squeeze() == y)/len(y)\n",
    "        \n",
    "        if (i == len(train_dl)):\n",
    "            train_loss = train_losses/len(train_dl)\n",
    "            train_acc = train_accs/len(train_dl)\n",
    "            \n",
    "            test_losses = 0\n",
    "            test_accs = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for X_test, y_test in test_dl:\n",
    "                    test_pred = model(X_test)\n",
    "                    test_loss = criterion(test_pred.squeeze(), y_test.float())\n",
    "                    test_losses += test_loss.item()\n",
    "                    test_accs += torch.sum(torch.where(test_pred > 0.5, 1, 0).squeeze() == y_test)/len(y_test)\n",
    "                \n",
    "                test_loss = test_losses/len(test_dl)\n",
    "                test_acc = test_accs/len(test_dl)\n",
    "                \n",
    "            print(f\"Epoch [{epoch}/{EPOCHS}]\")\n",
    "            print(f\"\\tIteration [{i}/{len(train_dl)}]\")\n",
    "            print(f\"\\t\\tTrain loss : {train_loss: .3f} || Test loss : {test_loss: .3f}\")\n",
    "            print(f\"\\t\\tTrain acc : {train_acc: .3f} || Test acc : {test_acc: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3896883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b8ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4c00dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e6fa87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6258b57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfdb4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebeae75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206cd7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.LSTM.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57515b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
